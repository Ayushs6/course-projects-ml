{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b876705",
      "metadata": {
        "id": "3b876705",
        "outputId": "e0fc1b1f-79a6-406c-ecbf-6ec6fc01d0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.20.0)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.7)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /Users/trippy/Library/Python/3.13/lib/python/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (6.33.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/trippy/Library/Python/3.13/lib/python/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (3.12.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/trippy/Library/Python/3.13/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/trippy/Library/Python/3.13/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow matplotlib numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9762d670",
      "metadata": {
        "id": "9762d670"
      },
      "source": [
        "# --------------------------------------------------\n",
        "# **Loading and preprocessing the MNIST dataset**\n",
        "# --------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d78e368b",
      "metadata": {
        "id": "d78e368b",
        "outputId": "04e9c1eb-f2db-43b9-ddda-a514cbb686f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: (60000, 28, 28, 1)\n",
            "Test  images: (10000, 28, 28, 1)\n",
            "Train labels: (60000,)\n",
            "Test  labels: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data = np.load(\"/Users/trippy/Library/CloudStorage/OneDrive-montclair.edu/Semester 2/Machine Learning/Assignments/Code/mnist.npz\")\n",
        "\n",
        "# Images and labels\n",
        "x_train, y_train = data[\"x_train\"], data[\"y_train\"]\n",
        "x_test, y_test = data[\"x_test\"], data[\"y_test\"]\n",
        "\n",
        "# Converting pixel values from [0, 255] to [0, 1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Adding channel dimension so each image is (28, 28, 1) instead of (28, 28)\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "print(\"Train images:\", x_train.shape)\n",
        "print(\"Test  images:\", x_test.shape)\n",
        "print(\"Train labels:\", y_train.shape)\n",
        "print(\"Test  labels:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4224f18",
      "metadata": {
        "id": "e4224f18"
      },
      "source": [
        "In the above cell, I loaded the MNIST dataset from a local mnist.npz file instead of downloading it from the internet. Training and test images (x_train, x_test) and labels (y_train, y_test) are extracted using NumPy.\n",
        "\n",
        "The images are then converted from integer pixel values in the range [0, 255] to floating-point values in [0, 1] by dividing by 255. Finally, I add a channel dimension so that each image has shape (28, 28, 1), which is the format expected by the convolutional and fully connected models in Keras.\n",
        "\n",
        "The printed shapes confirm that there are 60,000 training images and 10,000 test images, each with the correct dimensions and corresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fede14f6",
      "metadata": {
        "id": "fede14f6"
      },
      "source": [
        "\n",
        "# --------------------------------------------------\n",
        "\n",
        "# **Defining three-layer and five-layer perceptron architectures**\n",
        "This cell defines two helper functions, build_mlp_3 and build_mlp_5, which construct Multi-Layer Perceptron (MLP) models with different depths.\n",
        "\n",
        "# --------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d16720",
      "metadata": {
        "id": "38d16720"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def build_mlp_3(activation=\"relu\"):\n",
        "    \"\"\"\n",
        "    Three-layer perceptron for MNIST:\n",
        "    - Input → Flatten(28x28x1) to 784\n",
        "    - Hidden layer 1: 256 units\n",
        "    - Hidden layer 2: 128 units\n",
        "    - Output layer: 10 units (one per digit class) with softmax\n",
        "    \"\"\"\n",
        "    return keras.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        layers.Dense(256, activation=activation),\n",
        "        layers.Dense(128, activation=activation),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "def build_mlp_5(activation=\"relu\"):\n",
        "    \"\"\"\n",
        "    Five-layer perceptron for MNIST:\n",
        "    - More hidden layers and units than the 3-layer version\n",
        "      so we can see the effect of increased depth.\n",
        "    \"\"\"\n",
        "    return keras.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 1)),\n",
        "        layers.Dense(512, activation=activation),\n",
        "        layers.Dense(256, activation=activation),\n",
        "        layers.Dense(128, activation=activation),\n",
        "        layers.Dense(64, activation=activation),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d84cbf",
      "metadata": {
        "id": "55d84cbf"
      },
      "source": [
        "This defines two helper functions, build_mlp_3 and build_mlp_5, which construct Multi-Layer Perceptron (MLP) models with different depths:\n",
        "\n",
        "build_mlp_3(activation=...) creates a three-layer perceptron:\n",
        "\n",
        "\tFlatten input (28×28×1) → 784,\n",
        "\tHidden layer with 256 units,\n",
        "\tHidden layer with 128 units,\n",
        "\tOutput layer with 10 units and softmax activation for digit classification.\n",
        "\n",
        "build_mlp_5(activation=...) creates a deeper five-layer perceptron:\n",
        "\tFlatten input,\n",
        "\tHidden layers with 512, 256, 128, and 64 units,\n",
        "\tOutput layer with 10 units and softmax.\n",
        "\n",
        "Both functions accept a choice of activation function (\"relu\" or \"sigmoid\") for all hidden layers. These builders allow me to easily change the depth and activation of the perceptron for Parts A.1 to A.4."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8384c447",
      "metadata": {
        "id": "8384c447"
      },
      "source": [
        "# --------------------------------------------------\n",
        "# **Preparation – Training and evaluation helper for all models (Parts A and B)**\n",
        "# --------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcad3695",
      "metadata": {
        "id": "dcad3695"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_model(model, optimizer, epochs=5):\n",
        "    \"\"\"\n",
        "    Compiles the given model, trains it on MNIST,\n",
        "    and returns (test_accuracy, running_time_in_seconds).\n",
        "    \"\"\"\n",
        "\n",
        "    # Setting loss and metric for classification\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Train on training data, keeping 10% for validation\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=128,\n",
        "        validation_split=0.1,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    end = time.time()\n",
        "    elapsed = end - start\n",
        "\n",
        "    return test_acc, elapsed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c1234c",
      "metadata": {
        "id": "64c1234c"
      },
      "source": [
        "For any given model and optimizer, the function:\n",
        "\t1.\tCompiles the model with:\n",
        "\t•\tLoss: sparse_categorical_crossentropy (for integer digit labels 0–9),\n",
        "\t•\tMetric: accuracy.\n",
        "\t2.\tTrains the model on the training set for a chosen number of epochs (batch size 128), with 10% of the training data used as validation.\n",
        "\t3.\tEvaluates the trained model on the test set to compute the final test accuracy.\n",
        "\t4.\tMeasures total running time (training + evaluation) using time.time().\n",
        "\n",
        "It returns a pair: (test_accuracy, running_time_in_seconds).\n",
        "This function is reused across all perceptron and CNN experiments so that the results are comparable in Parts A and B."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "131def13",
      "metadata": {
        "id": "131def13"
      },
      "source": [
        "# --------------------------------------------------\n",
        "# ***PART A – MULTI-LAYER PERCEPTRON***\n",
        "# --------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638e3661",
      "metadata": {
        "id": "638e3661"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**A.1 Three-layer perceptron with ReLU activation and Adam optimizer**\n",
        "\n",
        "In this experiment (Part A.1), I train a three-layer perceptron using:\n",
        "Hidden layers: 256 and 128 units,\n",
        "ReLU activation in the hidden layers,\n",
        "Adam optimizer,\n",
        "5 training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e9bb61d",
      "metadata": {
        "id": "1e9bb61d",
        "outputId": "7c4df49e-7f2a-4aac-9574-4c45b7522a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2923 - val_accuracy: 0.9670 - val_loss: 0.1157\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 0.1090 - val_accuracy: 0.9730 - val_loss: 0.0843\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9789 - loss: 0.0702 - val_accuracy: 0.9765 - val_loss: 0.0784\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9849 - loss: 0.0496 - val_accuracy: 0.9788 - val_loss: 0.0726\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0371 - val_accuracy: 0.9807 - val_loss: 0.0721\n",
            "Three-layer MLP (ReLU + Adam) – test accuracy: 0.9787999987602234\n",
            "Three-layer MLP (ReLU + Adam) – running time (s): 3.0660860538482666\n"
          ]
        }
      ],
      "source": [
        "mlp_relu_adam = build_mlp_3(activation=\"relu\")\n",
        "\n",
        "acc_relu_adam, time_relu_adam = run_model(\n",
        "    mlp_relu_adam,\n",
        "    optimizer=\"adam\",\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "print(\"Three-layer MLP (ReLU + Adam) – test accuracy:\", acc_relu_adam)\n",
        "print(\"Three-layer MLP (ReLU + Adam) – running time (s):\", time_relu_adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f8001bb",
      "metadata": {
        "id": "1f8001bb"
      },
      "source": [
        "Test accuracy ≈ 0.9788 (97.88%)\n",
        "Running time ≈ 3.07 seconds\n",
        "\n",
        "This shows that a relatively shallow MLP with ReLU and Adam already performs very well on MNIST. It serves as a strong baseline for comparing other activation functions and optimizers in later parts of Part A."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d85ae518",
      "metadata": {
        "id": "d85ae518"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**A.2 – Three-layer perceptron with Sigmoid activation and Adam optimizer**\n",
        "\n",
        "In Part A.2, I keep the same three-layer perceptron architecture but change the hidden-layer activation function from ReLU to Sigmoid, while still using the Adam optimizer and 5 training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0106c375",
      "metadata": {
        "id": "0106c375",
        "outputId": "ae15e1ad-5f55-4145-e93f-08ea6221daac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.6299 - val_accuracy: 0.9348 - val_loss: 0.2397\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.2443 - val_accuracy: 0.9507 - val_loss: 0.1713\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1851 - val_accuracy: 0.9620 - val_loss: 0.1367\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1465 - val_accuracy: 0.9682 - val_loss: 0.1157\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9656 - loss: 0.1191 - val_accuracy: 0.9707 - val_loss: 0.1007\n",
            "Three-layer MLP (Sigmoid + Adam) – test accuracy: 0.963699996471405\n",
            "Three-layer MLP (Sigmoid + Adam) – running time (s): 3.3703339099884033\n"
          ]
        }
      ],
      "source": [
        "mlp_sigmoid_adam = build_mlp_3(activation=\"sigmoid\")\n",
        "\n",
        "acc_sigmoid_adam, time_sigmoid_adam = run_model(\n",
        "    mlp_sigmoid_adam,\n",
        "    optimizer=\"adam\",\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "print(\"Three-layer MLP (Sigmoid + Adam) – test accuracy:\", acc_sigmoid_adam)\n",
        "print(\"Three-layer MLP (Sigmoid + Adam) – running time (s):\", time_sigmoid_adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287f0bda",
      "metadata": {
        "id": "287f0bda"
      },
      "source": [
        "Test accuracy ≈ 0.9637 (96.37%)\n",
        "Running time ≈ 3.37 seconds\n",
        "\n",
        "Compared to the ReLU network in A.1, the Sigmoid network is slightly slower and less accurate.\n",
        "\n",
        "This suggests that ReLU is a better activation function than Sigmoid for this task, likely because it avoids saturation and vanishing-gradient issues during training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c3bdff3",
      "metadata": {
        "id": "8c3bdff3"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**Assignment A.3 – Three-layer perceptron with ReLU activation and SGD optimizer**\n",
        "\n",
        "In Part A.3, I return to the three-layer perceptron with ReLU activation, but change the optimizer from Adam to SGD (Stochastic Gradient Descent) with a learning rate of 0.01. The model is trained for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eccf0350",
      "metadata": {
        "id": "eccf0350",
        "outputId": "34a73b8c-14ce-49a0-90e0-b8abd5db240d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7165 - loss: 1.2302 - val_accuracy: 0.8823 - val_loss: 0.5597\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8719 - loss: 0.5048 - val_accuracy: 0.9117 - val_loss: 0.3569\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8926 - loss: 0.3914 - val_accuracy: 0.9183 - val_loss: 0.3003\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9041 - loss: 0.3439 - val_accuracy: 0.9247 - val_loss: 0.2687\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9106 - loss: 0.3149 - val_accuracy: 0.9297 - val_loss: 0.2488\n",
            "Three-layer MLP (ReLU + SGD) – test accuracy: 0.919700026512146\n",
            "Three-layer MLP (ReLU + SGD) – running time (s): 2.4648451805114746\n"
          ]
        }
      ],
      "source": [
        "mlp_relu_sgd = build_mlp_3(activation=\"relu\")\n",
        "\n",
        "acc_relu_sgd, time_relu_sgd = run_model(\n",
        "    mlp_relu_sgd,\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "print(\"Three-layer MLP (ReLU + SGD) – test accuracy:\", acc_relu_sgd)\n",
        "print(\"Three-layer MLP (ReLU + SGD) – running time (s):\", time_relu_sgd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9917252b",
      "metadata": {
        "id": "9917252b"
      },
      "source": [
        "Test accuracy ≈ 0.9197 (91.97%)\n",
        "Running time ≈ 2.46 seconds\n",
        "\n",
        "Although SGD is slightly faster than Adam, the accuracy drops significantly (from about 97.88% with Adam to about 91.97% with SGD). This indicates that Adam is a much more effective optimizer than SGD for this architecture and dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324f9cd3",
      "metadata": {
        "id": "324f9cd3"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**Assignment A.4 – Five-layer perceptron using the best activation function and optimizer**\n",
        "\n",
        "In Part A.4, I build a five-layer perceptron using the best activation function and optimizer found in Parts A.1 to A.3, which are ReLU (activation) and Adam (optimizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7a0301",
      "metadata": {
        "id": "ee7a0301",
        "outputId": "3bb06b30-76c1-4234-9051-8c22cb568805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2610 - val_accuracy: 0.9637 - val_loss: 0.1123\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0947 - val_accuracy: 0.9760 - val_loss: 0.0856\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0611 - val_accuracy: 0.9762 - val_loss: 0.0850\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0427 - val_accuracy: 0.9783 - val_loss: 0.0801\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0358 - val_accuracy: 0.9798 - val_loss: 0.0743\n",
            "Five-layer MLP (best config) – test accuracy: 0.9794999957084656\n",
            "Five-layer MLP (best config) – running time (s): 5.846661806106567\n"
          ]
        }
      ],
      "source": [
        "best_activation = \"relu\"\n",
        "best_optimizer_name = \"adam\"\n",
        "\n",
        "mlp_5_best = build_mlp_5(activation=best_activation)\n",
        "\n",
        "if best_optimizer_name == \"adam\":\n",
        "    chosen_optimizer = \"adam\"\n",
        "else:\n",
        "    chosen_optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "acc_mlp5, time_mlp5 = run_model(\n",
        "    mlp_5_best,\n",
        "    optimizer=chosen_optimizer,\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "print(\"Five-layer MLP (best config) – test accuracy:\", acc_mlp5)\n",
        "print(\"Five-layer MLP (best config) – running time (s):\", time_mlp5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15079d53",
      "metadata": {
        "id": "15079d53"
      },
      "source": [
        "This deeper network has hidden layers with 512, 256, 128, and 64 units before the final 10-class output layer.\n",
        "\n",
        "Training for 5 epochs results in:\n",
        "Test accuracy ≈ 0.9795 (97.95%)\n",
        "Running time ≈ 5.85 seconds\n",
        "\n",
        "Compared to the three-layer ReLU + Adam model from A.1 (97.88% accuracy, ~3.07 s), the five-layer version achieves a slightly higher accuracy but takes almost twice as long to train. This shows that increasing depth can improve performance, but at the cost of higher computational effort.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740796e0",
      "metadata": {
        "id": "740796e0"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**Assignment A.5 – Summary of observations for perceptron models**\n",
        "\n",
        "This cell summarizes the results of all perceptron experiments in Part A:\n",
        "\n",
        "Three-layer MLP (ReLU + Adam, A.1):\t   Accuracy = 97.88%, time = 3.07 s\n",
        "Three-layer MLP (Sigmoid + Adam, A.2): Accuracy = 96.37%, time = 3.37 s\n",
        "Three-layer MLP (ReLU + SGD, A.3):     Accuracy = 91.97%, time = 2.46 s\n",
        "Five-layer MLP (ReLU + Adam, A.4):     Accuracy = 97.95%, time = 5.85 s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3c4cbf",
      "metadata": {
        "id": "ef3c4cbf",
        "outputId": "4bbf065a-01e6-42ab-bbfa-26c6a5d2e032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three-layer MLP – ReLU + Adam   : accuracy = 0.9787999987602234 , time (s) = 3.0660860538482666\n",
            "Three-layer MLP – Sigmoid + Adam: accuracy = 0.963699996471405 , time (s) = 3.3703339099884033\n",
            "Three-layer MLP – ReLU + SGD    : accuracy = 0.919700026512146 , time (s) = 2.4648451805114746\n",
            "Five-layer MLP – best config    : accuracy = 0.9794999957084656 , time (s) = 5.846661806106567\n"
          ]
        }
      ],
      "source": [
        "print(\"Three-layer MLP  (ReLU + Adam) : accuracy =\", acc_relu_adam, \", time (s) =\", time_relu_adam)\n",
        "print(\"Three-layer MLP (Sigmoid + Adam) : accuracy =\", acc_sigmoid_adam, \", time (s) =\", time_sigmoid_adam)\n",
        "print(\"Three-layer MLP (ReLU + SGD) : accuracy =\", acc_relu_sgd, \", time (s) =\", time_relu_sgd)\n",
        "print(\"Five-layer MLP – best config (ReLU + Adam) : accuracy =\", acc_mlp5, \", time (s) =\", time_mlp5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30298e25",
      "metadata": {
        "id": "30298e25"
      },
      "source": [
        "From these results, the main observations are:\n",
        "Activation functions: ReLU clearly outperforms Sigmoid for this dataset.\n",
        "Optimizers: Adam is much more effective than SGD, giving significantly higher accuracy.\n",
        "Model depth: Increasing depth from three to five layers yields a small accuracy improvement but increases training time.\n",
        "\n",
        "These points directly address the impact of activation choice, optimizer, and depth on the performance of perceptron models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3f0910",
      "metadata": {
        "id": "5d3f0910"
      },
      "source": [
        "# --------------------------------------------------\n",
        "# ***PART B – CONVOLUTIONAL NEURAL NETWORKS***\n",
        "# --------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed1ca23",
      "metadata": {
        "id": "8ed1ca23"
      },
      "source": [
        "Defining CNN architectures:\n",
        "\n",
        "Simple 4-layer CNN and LeNet-5\n",
        "\n",
        "Simple 4-layer CNN (build_simple_cnn):\n",
        "Conv2D(32 filters, 3x3) + MaxPooling2D(2x2)\n",
        "Conv2D(64 filters, 3x3) + MaxPooling2D(2x2)\n",
        "Flatten to Dense(64) to Dense(10 with softmax)\n",
        "\n",
        "\n",
        "LeNet-5 style CNN (build_lenet5):\n",
        "Conv2D(6 filters, 5x5) + AveragePooling\n",
        "Conv2D(16 filters, 5x5) + AveragePooling\n",
        "Flatten to Dense(120) to Dense(84) to Dense(10 with softmax)\n",
        "\n",
        "LeNet-5 is a classic architecture originally proposed for handwritten digit recognition, making it a natural and efficient choice for the MNIST dataset.\n",
        "\n",
        "These architectures are then trained and evaluated in the following Part B experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a8d139",
      "metadata": {
        "id": "87a8d139"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_simple_cnn():\n",
        "    \"\"\"\n",
        "    Simple 4-layer CNN for MNIST:\n",
        "    - Conv(32) + MaxPool\n",
        "    - Conv(64) + MaxPool\n",
        "    - Dense(64) + Dense(10)\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D(pool_size=2),\n",
        "        layers.Conv2D(64, kernel_size=3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_lenet5():\n",
        "    \"\"\"\n",
        "    LeNet-5 style CNN for MNIST.\n",
        "    Original LeNet-5 was proposed for handwritten digit recognition,\n",
        "    so it fits this assignment very naturally.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        # C1: 6 feature maps, 5x5 kernel, same padding - output 28x28\n",
        "        layers.Conv2D(6, kernel_size=5, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)),\n",
        "        # S2: average pooling → 14x14\n",
        "        layers.AveragePooling2D(pool_size=2),\n",
        "        # C3: 16 feature maps, 5x5 kernel, valid padding - 10x10\n",
        "        layers.Conv2D(16, kernel_size=5, activation=\"relu\"),\n",
        "        # S4: average pooling → 5x5\n",
        "        layers.AveragePooling2D(pool_size=2),\n",
        "        # Flatten - 16 * 5 * 5 = 400 features\n",
        "        layers.Flatten(),\n",
        "        # F5 and F6 fully connected layers\n",
        "        layers.Dense(120, activation=\"relu\"),\n",
        "        layers.Dense(84, activation=\"relu\"),\n",
        "        # Output layer for 10 digit classes\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7706b157",
      "metadata": {
        "id": "7706b157"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**B.1 - Simple 4-layer CNN with Adam optimizer**\n",
        "\n",
        "In Part B.1, I train the simple 4-layer CNN (two convolution + pooling blocks followed by two dense layers) using the Adam optimizer for 5 training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5c9792",
      "metadata": {
        "id": "4e5c9792",
        "outputId": "5f3af0af-f38c-4d78-f594-1dc9a4480e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9254 - loss: 0.2556 - val_accuracy: 0.9800 - val_loss: 0.0675\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0715 - val_accuracy: 0.9852 - val_loss: 0.0549\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9841 - loss: 0.0511 - val_accuracy: 0.9878 - val_loss: 0.0451\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.0408 - val_accuracy: 0.9885 - val_loss: 0.0423\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0341 - val_accuracy: 0.9892 - val_loss: 0.0377\n",
            "Simple CNN (4-layer) – test accuracy: 0.9872000217437744\n",
            "Simple CNN (4-layer) – running time (s): 21.555065155029297\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cnn_simple = build_simple_cnn()\n",
        "\n",
        "acc_cnn_simple, time_cnn_simple = run_model(\n",
        "    cnn_simple,\n",
        "    optimizer=\"adam\",\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "print(\"Simple CNN (4-layer) – test accuracy:\", acc_cnn_simple)\n",
        "print(\"Simple CNN (4-layer) – running time (s):\", time_cnn_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27cfdc56",
      "metadata": {
        "id": "27cfdc56"
      },
      "source": [
        "Test accuracy ≈ 0.9872 (98.72%)\n",
        "Running time ≈ 21.56 seconds\n",
        "\n",
        "This CNN achieves higher accuracy than all MLP models from Part A, demonstrating the advantage of convolutional layers in capturing local spatial patterns in image data. However, it also takes more time to train compared to the perceptron models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dc04541",
      "metadata": {
        "id": "4dc04541"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**B.2 - LeNet-5 CNN (chosen architecture) with Adam optimizer**\n",
        "In Part B.2, I train the LeNet-5 style CNN using the Adam optimizer for 5 epochs. This architecture is chosen from the list {LeNet-5, AlexNet, VGG-16, GoogLeNet, ResNet-18} provided in the assignment, because it was originally proposed for handwritten digit recognition and is well-suited to the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c8c6cd",
      "metadata": {
        "id": "b9c8c6cd",
        "outputId": "c7f58304-02dc-4586-b445-bcb2090bee9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8849 - loss: 0.3962 - val_accuracy: 0.9635 - val_loss: 0.1302\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1175 - val_accuracy: 0.9790 - val_loss: 0.0739\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9764 - loss: 0.0777 - val_accuracy: 0.9825 - val_loss: 0.0588\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9821 - loss: 0.0584 - val_accuracy: 0.9850 - val_loss: 0.0497\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.0475 - val_accuracy: 0.9850 - val_loss: 0.0520\n",
            "LeNet-5 CNN – test accuracy: 0.98580002784729\n",
            "LeNet-5 CNN – running time (s): 13.691288232803345\n"
          ]
        }
      ],
      "source": [
        "cnn_lenet5 = build_lenet5()\n",
        "\n",
        "acc_lenet5, time_lenet5 = run_model(\n",
        "    cnn_lenet5,\n",
        "    optimizer=\"adam\",\n",
        "    epochs=5,\n",
        ")\n",
        "\n",
        "print(\"LeNet-5 CNN – test accuracy:\", acc_lenet5)\n",
        "print(\"LeNet-5 CNN – running time (s):\", time_lenet5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "814f520f",
      "metadata": {
        "id": "814f520f"
      },
      "source": [
        "Test accuracy ≈ 0.9858 (98.58%)\n",
        "Running time ≈ 13.69 seconds\n",
        "\n",
        "LeNet-5 performs slightly worse in accuracy than the simple 4-layer CNN (98.58% vs 98.72%), but it trains faster (≈13.69 s vs 21.56 s). Both CNNs clearly outperform the perceptron models from Part A, confirming the strength of convolutional architectures on image classification tasks like MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13631de",
      "metadata": {
        "id": "b13631de"
      },
      "source": [
        "# --------------------------------------------------\n",
        "# ***PART C – PERFORMANCE COMPARISON AND ANALYSIS***\n",
        "# --------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bcffc94",
      "metadata": {
        "id": "4bcffc94"
      },
      "source": [
        "# --------------------------------------------------\n",
        "**C.1 - Performance comparison among perceptrons, CNNs, and best classical model (Assignment 1)**\n",
        "In Part C.1, I compare three categories of models:\n",
        "1.\tThe best perceptron (MLP) from Part A,\n",
        "2.\tThe best CNN from Part B,\n",
        "3.\tThe best classical machine learning model from Assignment 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07413230",
      "metadata": {
        "id": "07413230",
        "outputId": "c2b808ec-e276-4428-ae50-8ea3dca9f8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP results:\n",
            "Three-layer MLP – ReLU + Adam   : 0.9787999987602234 , time (s): 3.0660860538482666\n",
            "Three-layer MLP – Sigmoid + Adam: 0.963699996471405 , time (s): 3.3703339099884033\n",
            "Three-layer MLP – ReLU + SGD    : 0.919700026512146 , time (s): 2.4648451805114746\n",
            "Five-layer MLP – best config    : 0.9794999957084656 , time (s): 5.846661806106567\n",
            "\n",
            "CNN results:\n",
            "Simple CNN (4-layer)            : 0.9872000217437744 , time (s): 21.555065155029297\n",
            "LeNet-5 CNN                     : 0.98580002784729 , time (s): 13.691288232803345\n",
            "\n",
            "Best model from Assignment 1 – accuracy: 0.9792\n"
          ]
        }
      ],
      "source": [
        "# Comparing MLPs, CNNs, and Assignment 1 model\n",
        "\n",
        "print(\"MLP results:\")\n",
        "print(\"Three-layer MLP – ReLU + Adam   :\", acc_relu_adam,    \", time (s):\", time_relu_adam)\n",
        "print(\"Three-layer MLP – Sigmoid + Adam:\", acc_sigmoid_adam, \", time (s):\", time_sigmoid_adam)\n",
        "print(\"Three-layer MLP – ReLU + SGD    :\", acc_relu_sgd,     \", time (s):\", time_relu_sgd)\n",
        "print(\"Five-layer MLP – best config    :\", acc_mlp5,         \", time (s):\", time_mlp5)\n",
        "\n",
        "print(\"\\nCNN results:\")\n",
        "print(\"Simple CNN (4-layer)            :\", acc_cnn_simple,   \", time (s):\", time_cnn_simple)\n",
        "print(\"LeNet-5 CNN                     :\", acc_lenet5,       \", time (s):\", time_lenet5)\n",
        "\n",
        "\n",
        "best_assignment1_accuracy = 0.9792\n",
        "\n",
        "print(\"\\nBest model from Assignment 1 – accuracy:\", best_assignment1_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4551840",
      "metadata": {
        "id": "b4551840"
      },
      "source": [
        "\n",
        "From the experiments:\n",
        "\t•\tBest MLP (Part A) – five-layer perceptron with ReLU activation and Adam optimizer (A.4):\n",
        "\t•\tAccuracy ≈ 97.95%, time ≈ 5.85 s\n",
        "\t•\tBest CNN (Part B) – simple 4-layer CNN (B.1):\n",
        "\t•\tAccuracy ≈ 98.72%, time ≈ 21.56 s\n",
        "\t•\tLeNet-5 CNN (Part B.2):\n",
        "\t•\tAccuracy ≈ 98.58%, time ≈ 13.69 s\n",
        "\t•\tBest classical model (Assignment 1) – SVM with RBF kernel:\n",
        "\t•\tAccuracy ≈ 97.92%\n",
        "\n",
        "From these results, I observe that:\n",
        "\t•\tThe best classical model (SVM with RBF) and the best MLP have very similar accuracy (around 97.9%), showing that classical methods and MLPs can both perform strongly on MNIST.\n",
        "\t•\tBoth CNNs (simple 4-layer CNN and LeNet-5) achieve higher accuracy than the MLP and SVM, demonstrating that convolutional architectures are more effective at leveraging the spatial structure in image data.\n",
        "\t•\tThe simple 4-layer CNN has the highest test accuracy overall (≈98.72%), while LeNet-5 provides a slightly lower accuracy but better training time compared to the 4-layer CNN.\n",
        "\n",
        "Overall, the comparison shows that CNNs are the best-performing family of models for MNIST in this assignment, followed by MLPs and classical models like SVM. CNNs offer superior accuracy at the cost of increased training time and model complexity."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}